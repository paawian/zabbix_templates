# Hadoop by HTTP template description

The template gets the Hadoop metrics from cluster's hosts (ResourceManager, NodeManagers, NameNode, DataNodes) by HTTP agent. You should define the IP address (or FQDN) and Web-UI port for the ResourceManager in {$HADOOP.RESOURCEMANAGER.HOST} and {$HADOOP.RESOURCEMANAGER.PORT} macros and for the NameNode in {$HADOOP.NAMENODE.HOST} and {$HADOOP.NAMENODE.PORT} macros respectively. Macros can be set in the template or overridden at the host level.

You can discuss this template or leave feedback on our forum https://www.zabbix.com/forum/zabbix-suggestions-and-feedback/413459-discussion-thread-for-official-zabbix-template-hadoop

Generated by official Zabbix template tool "Templator"

## Summary
* [items](#items)
* [macros](#macros)
* [triggers](#triggers)
* [discoveries](#discoveries)
  * [Discovery Data node discovery ](#discovery_data_node_discovery)
  * [Discovery Node manager discovery ](#discovery_node_manager_discovery)

<a name="items"></a>

## Items
| name | description | key | type | delay |
| ------------- |------------- |------------- |------------- |------------- |
| Get DataNodes states | no description | hadoop.datanodes.get | HTTP_AGENT | no delay |
| NameNode: Total blocks | Count of blocks tracked by NameNode. | hadoop.namenode.blocks_total | DEPENDENT | 0 |
| NameNode: Blocks allocable | Maximum number of blocks allocable. | hadoop.namenode.block_capacity | DEPENDENT | 0 |
| NameNode: Capacity remaining | Available capacity. | hadoop.namenode.capacity_remaining | DEPENDENT | 0 |
| NameNode: Corrupt blocks | Number of corrupt blocks. | hadoop.namenode.corrupt_blocks | DEPENDENT | 0 |
| NameNode: Total files | Total count of files tracked by the NameNode. | hadoop.namenode.files_total | DEPENDENT | 0 |
| Get NameNode stats | no description | hadoop.namenode.get | HTTP_AGENT | no delay |
| NameNode: Get info | no description | hadoop.namenode.info | DEPENDENT | 0 |
| NameNode: Missing blocks | Number of missing blocks. | hadoop.namenode.missing_blocks | DEPENDENT | 0 |
| NameNode: Dead DataNodes | Count of dead DataNodes. | hadoop.namenode.num_dead_data_nodes | DEPENDENT | 0 |
| NameNode: Alive DataNodes | Count of alive DataNodes. | hadoop.namenode.num_live_data_nodes | DEPENDENT | 0 |
| NameNode: Stale DataNodes | DataNodes that do not send a heartbeat within 30 seconds are marked as "stale". | hadoop.namenode.num_stale_data_nodes | DEPENDENT | 0 |
| NameNode: Block Pool Renaming | no description | hadoop.namenode.percent_block_pool_used | DEPENDENT | 0 |
| NameNode: Percent capacity remaining | Available capacity in percent. | hadoop.namenode.percent_remaining | DEPENDENT | 0 |
| NameNode: RPC queue & processing time | Average time spent on processing RPC requests. | hadoop.namenode.rpc_processing_time_avg | DEPENDENT | 0 |
| NameNode: Total load | The current number of concurrent file accesses (read/write) across all DataNodes. | hadoop.namenode.total_load | DEPENDENT | 0 |
| NameNode: Transactions since last checkpoint | Total number of transactions since last checkpoint. | hadoop.namenode.transactions_since_last_checkpoint | DEPENDENT | 0 |
| NameNode: Under-replicated blocks | The number of blocks with insufficient replication. | hadoop.namenode.under_replicated_blocks | DEPENDENT | 0 |
| NameNode: Uptime | no description | hadoop.namenode.uptime | DEPENDENT | 0 |
| NameNode: Failed volumes | Number of failed volumes. | hadoop.namenode.volume_failures_total | DEPENDENT | 0 |
| Get NodeManagers states | no description | hadoop.nodemanagers.get | HTTP_AGENT | no delay |
| Get ResourceManager stats | no description | hadoop.resourcemanager.get | HTTP_AGENT | no delay |
| ResourceManager: Get info | no description | hadoop.resourcemanager.info | DEPENDENT | 0 |
| ResourceManager: Active NMs | Number of Active NodeManagers. | hadoop.resourcemanager.num_active_nm | DEPENDENT | 0 |
| ResourceManager: Decommissioned NMs | Number of Decommissioned NodeManagers. | hadoop.resourcemanager.num_decommissioned_nm | DEPENDENT | 0 |
| ResourceManager: Decommissioning NMs | Number of Decommissioning NodeManagers. | hadoop.resourcemanager.num_decommissioning_nm | DEPENDENT | 0 |
| ResourceManager: Lost NMs | Number of Lost NodeManagers. | hadoop.resourcemanager.num_lost_nm | DEPENDENT | 0 |
| ResourceManager: Rebooted NMs | Number of Rebooted NodeManagers. | hadoop.resourcemanager.num_rebooted_nm | DEPENDENT | 0 |
| ResourceManager: Shutdown NMs | Number of Shutdown NodeManagers. | hadoop.resourcemanager.num_shutdown_nm | DEPENDENT | 0 |
| ResourceManager: Unhealthy NMs | Number of Unhealthy NodeManagers. | hadoop.resourcemanager.num_unhealthy_nm | DEPENDENT | 0 |
| ResourceManager: RPC queue & processing time | Average time spent on processing RPC requests. | hadoop.resourcemanager.rpc_processing_time_avg | DEPENDENT | 0 |
| ResourceManager: Uptime | no description | hadoop.resourcemanager.uptime | DEPENDENT | 0 |
| NameNode: Service response time | Hadoop NameNode API performance. | net.tcp.service.perf["tcp","{$HADOOP.NAMENODE.HOST}","{$HADOOP.NAMENODE.PORT}"] | SIMPLE | no delay |
| ResourceManager: Service response time | Hadoop ResourceManager API performance. | net.tcp.service.perf["tcp","{$HADOOP.RESOURCEMANAGER.HOST}","{$HADOOP.RESOURCEMANAGER.PORT}"] | SIMPLE | no delay |
| NameNode: Service status | Hadoop NameNode API port availability. | net.tcp.service["tcp","{$HADOOP.NAMENODE.HOST}","{$HADOOP.NAMENODE.PORT}"] | SIMPLE | no delay |
| ResourceManager: Service status | Hadoop ResourceManager API port availability. | net.tcp.service["tcp","{$HADOOP.RESOURCEMANAGER.HOST}","{$HADOOP.RESOURCEMANAGER.PORT}"] | SIMPLE | no delay |


<a name="macros"></a>

## Macros
| macro | value |
| ------------- |------------- |
| {$HADOOP.CAPACITY_REMAINING.MIN.WARN} | 20 |
| {$HADOOP.NAMENODE.HOST} | NameNode |
| {$HADOOP.NAMENODE.PORT} | 9870 |
| {$HADOOP.NAMENODE.RESPONSE_TIME.MAX.WARN} | 10s |
| {$HADOOP.RESOURCEMANAGER.HOST} | ResourceManager |
| {$HADOOP.RESOURCEMANAGER.PORT} | 8088 |
| {$HADOOP.RESOURCEMANAGER.RESPONSE_TIME.MAX.WARN} | 10s |


<a name="triggers"></a>

## Triggers
| name | priority | description | expression | tags | url |
| ------------- |------------- |------------- |------------- |------------- |------------- |
| NameNode: Cluster has missing blocks | AVERAGE | A missing block is far worse than a corrupt block, because a missing block cannot be recovered by copying a replica. | min(/Hadoop by HTTP/hadoop.namenode.missing_blocks,15m)>0 | [{"tag": "scope", "value": "notice"}] | no url |
| NameNode: Cluster has DataNodes in Dead state | AVERAGE | The death of a DataNode causes a flurry of network activity, as the NameNode initiates replication of blocks lost on the dead nodes. | min(/Hadoop by HTTP/hadoop.namenode.num_dead_data_nodes,5m)>0 | [{"tag": "scope", "value": "notice"}] | no url |
| NameNode: Cluster capacity remaining is low | WARNING | A good practice is to ensure that disk use never exceeds 80 percent capacity. | max(/Hadoop by HTTP/hadoop.namenode.percent_remaining,15m)<{$HADOOP.CAPACITY_REMAINING.MIN.WARN} | [{"tag": "scope", "value": "capacity"}] | no url |
| NameNode: Failed to fetch NameNode API page | WARNING | Zabbix has not received any data for items for the last 30 minutes. | nodata(/Hadoop by HTTP/hadoop.namenode.uptime,30m)=1 | [{"tag": "scope", "value": "availability"}] | no url |
| NameNode: Service has been restarted | INFO | Uptime is less than 10 minutes. | last(/Hadoop by HTTP/hadoop.namenode.uptime)<10m | [{"tag": "scope", "value": "notice"}] | no url |
| NameNode: Cluster has volume failures | AVERAGE | HDFS now allows for disks to fail in place, without affecting DataNode operations, until a threshold value is reached. This is set on each DataNode via the dfs.datanode.failed.volumes.tolerated property; it defaults to 0, meaning that any volume failure will shut down the DataNode; on a production cluster where DataNodes typically have 6, 8, or 12 disks, setting this parameter to 1 or 2 is typically the best practice. | min(/Hadoop by HTTP/hadoop.namenode.volume_failures_total,15m)>0 | [{"tag": "scope", "value": "notice"}] | no url |
| ResourceManager: Cluster has no active NodeManagers | HIGH | Cluster is unable to execute any jobs without at least one NodeManager. | max(/Hadoop by HTTP/hadoop.resourcemanager.num_active_nm,5m)=0 | [{"tag": "scope", "value": "notice"}] | no url |
| ResourceManager: Cluster has unhealthy NodeManagers | AVERAGE | YARN considers any node with disk utilization exceeding the value specified under the property yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage (in yarn-site.xml) to be unhealthy. Ample disk space is critical to ensure uninterrupted operation of a Hadoop cluster, and large numbers of unhealthyNodes (the number to alert on depends on the size of your cluster) should be quickly investigated and resolved. | min(/Hadoop by HTTP/hadoop.resourcemanager.num_unhealthy_nm,15m)>0 | [{"tag": "scope", "value": "notice"}] | no url |
| ResourceManager: Failed to fetch ResourceManager API page | WARNING | Zabbix has not received any data for items for the last 30 minutes. | nodata(/Hadoop by HTTP/hadoop.resourcemanager.uptime,30m)=1 | [{"tag": "scope", "value": "availability"}] | no url |
| ResourceManager: Service has been restarted | INFO | Uptime is less than 10 minutes. | last(/Hadoop by HTTP/hadoop.resourcemanager.uptime)<10m | [{"tag": "scope", "value": "notice"}] | no url |
| NameNode: Service response time is too high | WARNING | no description | min(/Hadoop by HTTP/net.tcp.service.perf["tcp","{$HADOOP.NAMENODE.HOST}","{$HADOOP.NAMENODE.PORT}"],5m)>{$HADOOP.NAMENODE.RESPONSE_TIME.MAX.WARN} | [{"tag": "scope", "value": "performance"}] | no url |
| ResourceManager: Service response time is too high | WARNING | no description | min(/Hadoop by HTTP/net.tcp.service.perf["tcp","{$HADOOP.RESOURCEMANAGER.HOST}","{$HADOOP.RESOURCEMANAGER.PORT}"],5m)>{$HADOOP.RESOURCEMANAGER.RESPONSE_TIME.MAX.WARN} | [{"tag": "scope", "value": "performance"}] | no url |
| NameNode: Service is unavailable | AVERAGE | no description | last(/Hadoop by HTTP/net.tcp.service["tcp","{$HADOOP.NAMENODE.HOST}","{$HADOOP.NAMENODE.PORT}"])=0 | [{"tag": "scope", "value": "availability"}] | no url |
| ResourceManager: Service is unavailable | AVERAGE | no description | last(/Hadoop by HTTP/net.tcp.service["tcp","{$HADOOP.RESOURCEMANAGER.HOST}","{$HADOOP.RESOURCEMANAGER.PORT}"])=0 | [{"tag": "scope", "value": "availability"}] | no url |


<a name="discoveries"></a>

## Discoveries
| name | key | description | type | lifetime | delay |
| ------------- |------------- |------------- |------------- |------------- |------------- |
| Data node discovery | hadoop.datanode.discovery | no description | HTTP_AGENT | no lifetime | 1h |
| Node manager discovery | hadoop.nodemanager.discovery | no description | HTTP_AGENT | no lifetime | 1h |


<a name="discovery_data_node_discovery" />

## Discovery Data node discovery

### Items

| name | description | key | type |
| ------------- |------------- |------------- |------------- |
| {#HOSTNAME}: Admin state | Administrative state. | hadoop.datanode.admin_state[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: Used | Used disk space. | hadoop.datanode.dfs_used[{#HOSTNAME}] | DEPENDENT |
| Hadoop DataNode {#HOSTNAME}: Get stats | no description | hadoop.datanode.get[{#HOSTNAME}] | HTTP_AGENT |
| {#HOSTNAME}: JVM Garbage collection time | The JVM garbage collection time in milliseconds. | hadoop.datanode.jvm.gc_time[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: JVM Heap usage | The JVM heap usage in MBytes. | hadoop.datanode.jvm.mem_heap_used[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: JVM Threads | The number of JVM threads. | hadoop.datanode.jvm.threads[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: Number of failed volumes | Number of failed storage volumes. | hadoop.datanode.numfailedvolumes[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: Oper state | Operational state. | hadoop.datanode.oper_state[{#HOSTNAME}] | DEPENDENT |
| Hadoop DataNode {#HOSTNAME}: Get raw info | no description | hadoop.datanode.raw_info[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: Remaining | Remaining disk space. | hadoop.datanode.remaining[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: Uptime | no description | hadoop.datanode.uptime[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: Version | DataNode software version. | hadoop.datanode.version[{#HOSTNAME}] | DEPENDENT |


### Triggers

| name | priority | description | expression | tags | url |
| ------------- |------------- |------------- |------------- |------------- |------------- |
| {#HOSTNAME}: DataNode has state {ITEM.VALUE}. | AVERAGE | The state is different from normal. | last(/Hadoop by HTTP/hadoop.datanode.oper_state[{#HOSTNAME}])<>"Live" | [{"tag": "scope", "value": "notice"}] | no url |
| {#HOSTNAME}: Failed to fetch DataNode API page | WARNING | Zabbix has not received any data for items for the last 30 minutes. | nodata(/Hadoop by HTTP/hadoop.datanode.uptime[{#HOSTNAME}],30m)=1 | [{"tag": "scope", "value": "availability"}] | no url |
| {#HOSTNAME}: Service has been restarted | INFO | Uptime is less than 10 minutes. | last(/Hadoop by HTTP/hadoop.datanode.uptime[{#HOSTNAME}])<10m | [{"tag": "scope", "value": "notice"}] | no url |


<a name="discovery_node_manager_discovery" />

## Discovery Node manager discovery

### Items

| name | description | key | type |
| ------------- |------------- |------------- |------------- |
| {#HOSTNAME}: Available memory | no description | hadoop.nodemanager.availablememory[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: Container launch avg duration | no description | hadoop.nodemanager.container_launch_duration_avg[{#HOSTNAME}] | DEPENDENT |
| Hadoop NodeManager {#HOSTNAME}: Get stats | no description | hadoop.nodemanager.get[{#HOSTNAME}] | HTTP_AGENT |
| {#HOSTNAME}: JVM Garbage collection time | The JVM garbage collection time in milliseconds. | hadoop.nodemanager.jvm.gc_time[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: JVM Heap usage | The JVM heap usage in MBytes. | hadoop.nodemanager.jvm.mem_heap_used[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: JVM Threads | The number of JVM threads. | hadoop.nodemanager.jvm.threads[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: Number of containers | no description | hadoop.nodemanager.numcontainers[{#HOSTNAME}] | DEPENDENT |
| Hadoop NodeManager {#HOSTNAME}: Get raw info | no description | hadoop.nodemanager.raw_info[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: RPC queue & processing time | Average time spent on processing RPC requests. | hadoop.nodemanager.rpc_processing_time_avg[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: State | State of the node - valid values are: NEW, RUNNING, UNHEALTHY, DECOMMISSIONING, DECOMMISSIONED, LOST, REBOOTED, SHUTDOWN. | hadoop.nodemanager.state[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: Uptime | no description | hadoop.nodemanager.uptime[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: Used memory | no description | hadoop.nodemanager.usedmemory[{#HOSTNAME}] | DEPENDENT |
| {#HOSTNAME}: Version | no description | hadoop.nodemanager.version[{#HOSTNAME}] | DEPENDENT |


### Triggers

| name | priority | description | expression | tags | url |
| ------------- |------------- |------------- |------------- |------------- |------------- |
| {#HOSTNAME}: NodeManager has state {ITEM.VALUE}. | AVERAGE | The state is different from normal. | last(/Hadoop by HTTP/hadoop.nodemanager.state[{#HOSTNAME}])<>"RUNNING" | [{"tag": "scope", "value": "notice"}] | no url |
| {#HOSTNAME}: Failed to fetch NodeManager API page | WARNING | Zabbix has not received any data for items for the last 30 minutes. | nodata(/Hadoop by HTTP/hadoop.nodemanager.uptime[{#HOSTNAME}],30m)=1 | [{"tag": "scope", "value": "availability"}] | no url |
| {#HOSTNAME}: Service has been restarted | INFO | Uptime is less than 10 minutes. | last(/Hadoop by HTTP/hadoop.nodemanager.uptime[{#HOSTNAME}])<10m | [{"tag": "scope", "value": "notice"}] | no url |

