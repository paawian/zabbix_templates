# ClickHouse by HTTP template description

This template is designed for the effortless deployment of ClickHouse monitoring by Zabbix via HTTP and doesn't require any external scripts.

Setup:

1. Create a user to monitor the service. For example, you could create a file '/etc/clickhouse-server/users.d/zabbix.xml' with the following content:

<yandex>
  <users>
    <zabbix>
      <password>zabbix_pass</password>
      <networks incl="networks" />
      <profile>web</profile>
      <quota>default</quota>
      <allow_databases>
        <database>test</database>
      </allow_databases>
    </zabbix>
  </users>
</yandex>

2. Set the hostname or IP address of the ClickHouse HTTP endpoint in the '{$CLICKHOUSE.HOST}' macro. You can also change the port in the '{$CLICKHOUSE.PORT}' macro and scheme in the '{$CLICKHOUSE.SCHEME}' macro if necessary.

3. Set the login and password in the macros '{$CLICKHOUSE.USER}' and '{$CLICKHOUSE.PASSWORD}'. If you don't need an authentication - remove headers from HTTP-Agent type items.

Generated by official Zabbix template tool "Templator"

## Summary
* [items](#items)
* [macros](#macros)
* [triggers](#triggers)
* [discoveries](#discoveries)
  * [Discovery Databases ](#discovery_databases)
  * [Discovery Dictionaries ](#discovery_dictionaries)
  * [Discovery Replicas ](#discovery_replicas)
  * [Discovery Tables ](#discovery_tables)

<a name="items"></a>

## Items
| name | description | key | type | delay |
| ------------- |------------- |------------- |------------- |------------- |
| Current distribute connections | Number of connections to remote servers sending data that was INSERTed into Distributed tables. | clickhouse.connections.distribute | DEPENDENT | 0 |
| Current HTTP connections | Number of connections to HTTP server. | clickhouse.connections.http | DEPENDENT | 0 |
| Current Interserver connections | Number of connections from other replicas to fetch parts. | clickhouse.connections.interserver | DEPENDENT | 0 |
| Current MySQL connections | Number of connections to MySQL server. | clickhouse.connections.mysql | DEPENDENT | 0 |
| Current TCP connections | Number of connections to TCP server (clients with native interface). | clickhouse.connections.tcp | DEPENDENT | 0 |
| Get databases info | Get information about databases. | clickhouse.databases | HTTP_AGENT | no delay |
| Get dictionaries info | Get information about dictionaries. | clickhouse.dictionaries | HTTP_AGENT | no delay |
| Current distributed files to insert | Number of pending files to process for asynchronous insertion into Distributed tables. Number of files for every shard is summed. | clickhouse.distributed.files | DEPENDENT | 0 |
| Distributed connection fail with retry per second | Connection failures after all retries in replicated DB connection pool | clickhouse.distributed.files.fail.rate | DEPENDENT | 0 |
| Distributed connection fail with retry per second | Connection retries in replicated DB connection pool | clickhouse.distributed.files.retry.rate | DEPENDENT | 0 |
| Delayed insert queries | Number of INSERT queries that are throttled due to high number of active data parts for partition in a MergeTree table. | clickhouse.insert.delay | DEPENDENT | 0 |
| Inserted bytes per second | The number of uncompressed bytes inserted in all tables. | clickhouse.inserted_bytes.rate | DEPENDENT | 0 |
| Inserted rows per second | The number of rows inserted in all tables. | clickhouse.inserted_rows.rate | DEPENDENT | 0 |
| New INSERT queries per second | Number of INSERT queries to be interpreted and potentially executed. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries. | clickhouse.insert_query.rate | DEPENDENT | 0 |
| Allocated bytes | Total number of bytes allocated by the application. | clickhouse.jemalloc.allocated | DEPENDENT | 0 |
| Mapped memory | Total number of bytes in active extents mapped by the allocator. | clickhouse.jemalloc.mapped | DEPENDENT | 0 |
| Resident memory | Maximum number of bytes in physically resident data pages mapped by the allocator,<br>comprising all pages dedicated to allocator metadata, pages backing active allocations,<br>and unused dirty pages. | clickhouse.jemalloc.resident | DEPENDENT | 0 |
| Max count of parts per partition across all tables | Clickhouse MergeTree table engine split each INSERT query to partitions (PARTITION BY expression) and add one or more PARTS per INSERT inside each partition, after that background merge process run. | clickhouse.max.part.count.for.partition | DEPENDENT | 0 |
| Memory used for queries | Total amount of memory (bytes) allocated in currently executing queries. | clickhouse.memory.tracking | DEPENDENT | 0 |
| Memory used for background merges | Total amount of memory (bytes) allocated in background processing pool (that is dedicated for background merges, mutations and fetches).<br> Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa. This happens naturally due to caches for tables indexes and doesn't indicate memory leaks. | clickhouse.memory.tracking.background | DEPENDENT | 0 |
| Memory used for background moves | Total amount of memory (bytes) allocated in background processing pool (that is dedicated for background moves). Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa.<br> This happens naturally due to caches for tables indexes and doesn't indicate memory leaks. | clickhouse.memory.tracking.background.moves | DEPENDENT | 0 |
| Memory used for merges | Total amount of memory (bytes) allocated for background merges. Included in MemoryTrackingInBackgroundProcessingPool. Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa.<br>This happens naturally due to caches for tables indexes and doesn't indicate memory leaks. | clickhouse.memory.tracking.merges | DEPENDENT | 0 |
| Memory used for background schedule pool | Total amount of memory (bytes) allocated in background schedule pool (that is dedicated for bookkeeping tasks of Replicated tables). | clickhouse.memory.tracking.schedule.pool | DEPENDENT | 0 |
| Current running merges | Number of executing background merges | clickhouse.merge.current | DEPENDENT | 0 |
| Uncompressed bytes merged per second | Uncompressed bytes that were read for background merges | clickhouse.merge_bytes.rate | DEPENDENT | 0 |
| Merged rows per second | Rows read for background merges. | clickhouse.merge_rows.rate | DEPENDENT | 0 |
| Network errors per second | Network errors (timeouts and connection failures) during query execution, background pool tasks and DNS cache update. | clickhouse.network.error.rate | DEPENDENT | 0 |
| Ping | no description | clickhouse.ping | HTTP_AGENT | no delay |
| Longest currently running query time | Get longest running query. | clickhouse.process.elapsed | HTTP_AGENT | no delay |
| Current running queries | Number of executing queries | clickhouse.query.current | DEPENDENT | 0 |
| New queries per second | Number of queries to be interpreted and potentially executed. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries. | clickhouse.query.rate | DEPENDENT | 0 |
| Read syscalls in fly | Number of read (read, pread, io_getevents, etc.) syscalls in fly | clickhouse.read | DEPENDENT | 0 |
| Read bytes per second | Number of bytes (the number of bytes before decompression) read from compressed sources (files, network). | clickhouse.read_bytes.rate | DEPENDENT | 0 |
| Get replicas info | Get information about replicas. | clickhouse.replicas | HTTP_AGENT | no delay |
| Replication lag across all tables | Maximum replica queue delay relative to current time | clickhouse.replicas.max.absolute.delay | DEPENDENT | 0 |
| Total number read-only Replicas | Number of Replicated tables that are currently in readonly state due to re-initialization after ZooKeeper session loss or due to startup without ZooKeeper configured. | clickhouse.replicas.readonly.total | DEPENDENT | 0 |
| Total replication tasks in queue | Number of replication tasks in queue | clickhouse.replicas.sum.queue.size | DEPENDENT | 0 |
| Revision | Revision of the server. | clickhouse.revision | DEPENDENT | 0 |
| New SELECT queries per second | Number of SELECT queries to be interpreted and potentially executed. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries. | clickhouse.select_query.rate | DEPENDENT | 0 |
| Get system.asynchronous_metrics | Get metrics that are calculated periodically in the background | clickhouse.system.asynchronous_metrics | HTTP_AGENT | no delay |
| Get system.events | Get information about the number of events that have occurred in the system. | clickhouse.system.events | HTTP_AGENT | no delay |
| Get system.metrics | Get metrics which can be calculated instantly, or have a current value format JSONEachRow | clickhouse.system.metrics | HTTP_AGENT | no delay |
| Get system.settings | Get information about settings that are currently in use. | clickhouse.system.settings | HTTP_AGENT | no delay |
| Get tables info | Get information about tables. | clickhouse.tables | HTTP_AGENT | no delay |
| Uptime | Number of seconds since ClickHouse server start | clickhouse.uptime | DEPENDENT | 0 |
| Version | Version of the server | clickhouse.version | HTTP_AGENT | no delay |
| Write syscalls in fly | Number of write (write, pwrite, io_getevents, etc.) syscalls in fly | clickhouse.write | DEPENDENT | 0 |
| ZooKeeper exceptions per second | Count of ZooKeeper exceptions that does not belong to user/hardware exceptions. | clickhouse.zookeeper.exceptions.rate | DEPENDENT | 0 |
| ZooKeeper hardware exceptions per second | Count of ZooKeeper exceptions caused by session moved/expired, connection loss, marshalling error, operation timed out and invalid zhandle state. | clickhouse.zookeeper.hw_exceptions.rate | DEPENDENT | 0 |
| ZooKeeper requests | Number of requests to ZooKeeper in progress. | clickhouse.zookeeper.request | DEPENDENT | 0 |
| ZooKeeper sessions | Number of sessions (connections) to ZooKeeper. Should be no more than one. | clickhouse.zookeeper.session | DEPENDENT | 0 |
| ZooKeeper user exceptions per second | Count of ZooKeeper exceptions caused by no znodes, bad version, node exists, node empty and no children for ephemeral. | clickhouse.zookeeper.user_exceptions.rate | DEPENDENT | 0 |
| ZooKeeper wait time | Time spent in waiting for ZooKeeper operations. | clickhouse.zookeeper.wait.time | DEPENDENT | 0 |
| ZooKeeper watches | Number of watches (e.g., event subscriptions) in ZooKeeper. | clickhouse.zookeeper.watch | DEPENDENT | 0 |
| Check port availability | no description | net.tcp.service[{$CLICKHOUSE.SCHEME},"{$CLICKHOUSE.HOST}","{$CLICKHOUSE.PORT}"] | SIMPLE | no delay |


<a name="macros"></a>

## Macros
| macro | value |
| ------------- |------------- |
| {$CLICKHOUSE.DELAYED.FILES.DISTRIBUTED.COUNT.MAX.WARN} | 600 |
| {$CLICKHOUSE.DELAYED.INSERTS.MAX.WARN} | 0 |
| {$CLICKHOUSE.HOST} | <SET CLICKHOUSE HOST> |
| {$CLICKHOUSE.LLD.FILTER.DB.MATCHES} | .* |
| {$CLICKHOUSE.LLD.FILTER.DB.NOT_MATCHES} | CHANGE_IF_NEEDED |
| {$CLICKHOUSE.LLD.FILTER.DICT.MATCHES} | .* |
| {$CLICKHOUSE.LLD.FILTER.DICT.NOT_MATCHES} | CHANGE_IF_NEEDED |
| {$CLICKHOUSE.LLD.FILTER.TABLE.MATCHES} | .* |
| {$CLICKHOUSE.LLD.FILTER.TABLE.NOT_MATCHES} | CHANGE_IF_NEEDED |
| {$CLICKHOUSE.LOG_POSITION.DIFF.MAX.WARN} | 30 |
| {$CLICKHOUSE.NETWORK.ERRORS.MAX.WARN} | 5 |
| {$CLICKHOUSE.PARTS.PER.PARTITION.WARN} | 300 |
| {$CLICKHOUSE.PASSWORD} | zabbix_pass |
| {$CLICKHOUSE.PORT} | 8123 |
| {$CLICKHOUSE.QUERY_TIME.MAX.WARN} | 600 |
| {$CLICKHOUSE.QUEUE.SIZE.MAX.WARN} | 20 |
| {$CLICKHOUSE.REPLICA.MAX.WARN} | 600 |
| {$CLICKHOUSE.SCHEME} | http |
| {$CLICKHOUSE.USER} | zabbix |


<a name="triggers"></a>

## Triggers
| name | priority | description | expression | tags | url |
| ------------- |------------- |------------- |------------- |------------- |------------- |
| Too many distributed files to insert | WARNING | Clickhouse servers and <remote_servers> in config.xml (https://clickhouse.tech/docs/en/operations/table_engines/distributed/) | min(/ClickHouse by HTTP/clickhouse.distributed.files,5m)>{$CLICKHOUSE.DELAYED.FILES.DISTRIBUTED.COUNT.MAX.WARN} | [{"tag": "scope", "value": "capacity"}] | no url |
| Too many throttled insert queries | WARNING | Clickhouse have INSERT queries that are throttled due to high number of active data parts for partition in a MergeTree, please decrease INSERT frequency | min(/ClickHouse by HTTP/clickhouse.insert.delay,5m)>{$CLICKHOUSE.DELAYED.INSERTS.MAX.WARN} | [{"tag": "scope", "value": "performance"}] | no url |
| Too many MergeTree parts | WARNING | Descease INSERT queries frequency.<br>Clickhouse MergeTree table engine split each INSERT query to partitions (PARTITION BY expression)<br>and add one or more PARTS per INSERT inside each partition,<br>after that background merge process run, and when you have too much unmerged parts inside partition,<br>SELECT queries performance can significate degrade, so clickhouse try delay insert, or abort it. | min(/ClickHouse by HTTP/clickhouse.max.part.count.for.partition,5m)>{$CLICKHOUSE.PARTS.PER.PARTITION.WARN} * 0.9 | [{"tag": "scope", "value": "performance"}] | no url |
| Too many network errors | WARNING | Number of errors (timeouts and connection failures) during query execution, background pool tasks and DNS cache update is too high. | min(/ClickHouse by HTTP/clickhouse.network.error.rate,5m)>{$CLICKHOUSE.NETWORK.ERRORS.MAX.WARN} | [{"tag": "scope", "value": "availability"}] | no url |
| There are queries running is long | AVERAGE | no description | last(/ClickHouse by HTTP/clickhouse.process.elapsed)>{$CLICKHOUSE.QUERY_TIME.MAX.WARN} | [{"tag": "scope", "value": "performance"}] | no url |
| Replication lag is too high | WARNING | When replica have too much lag, it can be skipped from Distributed SELECT Queries without errors<br>and you will have wrong query results. | min(/ClickHouse by HTTP/clickhouse.replicas.max.absolute.delay,5m)>{$CLICKHOUSE.REPLICA.MAX.WARN} | [{"tag": "scope", "value": "performance"}] | no url |
| Configuration has been changed | INFO | ClickHouse configuration has been changed. Acknowledge to close the problem manually. | last(/ClickHouse by HTTP/clickhouse.system.settings,#1)<>last(/ClickHouse by HTTP/clickhouse.system.settings,#2) and length(last(/ClickHouse by HTTP/clickhouse.system.settings))>0 | [{"tag": "scope", "value": "notice"}] | no url |
| Failed to fetch info data | WARNING | Zabbix has not received any data for items for the last 30 minutes. | nodata(/ClickHouse by HTTP/clickhouse.uptime,30m)=1 | [{"tag": "scope", "value": "notice"}] | no url |
| Host has been restarted | INFO | The host uptime is less than 10 minutes. | last(/ClickHouse by HTTP/clickhouse.uptime)<10m | [{"tag": "scope", "value": "notice"}] | no url |
| Version has changed | INFO | The ClickHouse version has changed. Acknowledge to close the problem manually. | last(/ClickHouse by HTTP/clickhouse.version,#1)<>last(/ClickHouse by HTTP/clickhouse.version,#2) and length(last(/ClickHouse by HTTP/clickhouse.version))>0 | [{"tag": "scope", "value": "notice"}] | no url |
| Too many ZooKeeper sessions opened | WARNING | Number of sessions (connections) to ZooKeeper.<br>Should be no more than one, because using more than one connection to ZooKeeper may lead to bugs due to lack of linearizability (stale reads) that ZooKeeper consistency model allows. | min(/ClickHouse by HTTP/clickhouse.zookeeper.session,5m)>1 | [{"tag": "scope", "value": "performance"}] | no url |
| Port {$CLICKHOUSE.PORT} is unavailable | AVERAGE | no description | last(/ClickHouse by HTTP/net.tcp.service[{$CLICKHOUSE.SCHEME},"{$CLICKHOUSE.HOST}","{$CLICKHOUSE.PORT}"])=0 | [{"tag": "scope", "value": "availability"}] | no url |
| Service is down | AVERAGE | no description | last(/ClickHouse by HTTP/clickhouse.ping)=0 or last(/ClickHouse by HTTP/net.tcp.service[{$CLICKHOUSE.SCHEME},"{$CLICKHOUSE.HOST}","{$CLICKHOUSE.PORT}"]) = 0 | [{"tag": "scope", "value": "availability"}] | no url |


<a name="discoveries"></a>

## Discoveries
| name | key | description | type | lifetime | delay |
| ------------- |------------- |------------- |------------- |------------- |------------- |
| Databases | clickhouse.db.discovery | Info about databases | DEPENDENT | no lifetime | 0 |
| Dictionaries | clickhouse.dictionaries.discovery | Info about dictionaries | DEPENDENT | no lifetime | 0 |
| Replicas | clickhouse.replicas.discovery | Info about replicas | DEPENDENT | no lifetime | 0 |
| Tables | clickhouse.tables.discovery | Info about tables | DEPENDENT | no lifetime | 0 |


<a name="discovery_databases"></a>

## Discovery Databases

### Items

| name | description | key | type |
| ------------- |------------- |------------- |------------- |
| {#DB}: Bytes | Database size in bytes. | clickhouse.db.bytes["{#DB}"] | DEPENDENT |
| {#DB}: Get DB info | The item gets information about {#DB} database. | clickhouse.db.info_raw["{#DB}"] | DEPENDENT |
| {#DB}: Tables | Number of tables in {#DB} database. | clickhouse.db.tables["{#DB}"] | DEPENDENT |


<a name="discovery_dictionaries"></a>

## Discovery Dictionaries

### Items

| name | description | key | type |
| ------------- |------------- |------------- |------------- |
| Dictionary {#NAME}: Bytes allocated | The amount of RAM the dictionary uses. | clickhouse.dictionary.bytes_allocated["{#NAME}"] | DEPENDENT |
| Dictionary {#NAME}: Element count | Number of items stored in the dictionary. | clickhouse.dictionary.element_count["{#NAME}"] | DEPENDENT |
| Dictionary {#NAME}: Get dictionary info | The item gets information about {#NAME} dictionary. | clickhouse.dictionary.info_raw["{#NAME}"] | DEPENDENT |
| Dictionary {#NAME}: Load factor | The percentage filled in the dictionary (for a hashed dictionary, the percentage filled in the hash table). | clickhouse.dictionary.load_factor["{#NAME}"] | DEPENDENT |


<a name="discovery_replicas"></a>

## Discovery Replicas

### Items

| name | description | key | type |
| ------------- |------------- |------------- |------------- |
| {#DB}.{#TABLE}: Active replicas | Number of replicas of this table that have a session in ZooKeeper (i.e., the number of functioning replicas). (Have a non-zero value only where there is an active session with ZooKeeper). | clickhouse.replica.active_replicas["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Replica future parts | Number of data parts that will appear as the result of INSERTs or merges that haven't been done yet. | clickhouse.replica.future_parts["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Get replicas info | The item gets information about replicas of {#TABLE} table of {#DB} database. | clickhouse.replica.info_raw["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Replica queue inserts size | Number of inserts of blocks of data that need to be made. | clickhouse.replica.inserts_in_queue["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Replica readonly | Whether the replica is in read-only mode.<br>This mode is turned on if the config doesn't have sections with ZooKeeper, if an unknown error occurred when re-initializing sessions in ZooKeeper, and during session re-initialization in ZooKeeper. | clickhouse.replica.is_readonly["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Replica session expired | True if the ZooKeeper session expired | clickhouse.replica.is_session_expired["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Replica lag | Difference between log_max_index and log_pointer | clickhouse.replica.lag["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Replica log max index | Maximum entry number in the log of general activity. (Have a non-zero value only where there is an active session with ZooKeeper). | clickhouse.replica.log_max_index["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Replica log pointer | Maximum entry number in the log of general activity that the replica copied to its execution queue, plus one. (Have a non-zero value only where there is an active session with ZooKeeper). | clickhouse.replica.log_pointer["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Replica queue merges size | Number of merges waiting to be made. | clickhouse.replica.merges_in_queue["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Replica parts to check | Number of data parts in the queue for verification. A part is put in the verification queue if there is suspicion that it might be damaged. | clickhouse.replica.parts_to_check["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Replica queue size | Size of the queue for operations waiting to be performed. | clickhouse.replica.queue_size["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Total replicas | Total number of known replicas of this table. (Have a non-zero value only where there is an active session with ZooKeeper). | clickhouse.replica.total_replicas["{#DB}.{#TABLE}"] | DEPENDENT |


### Triggers

| name | priority | description | expression | tags | url |
| ------------- |------------- |------------- |------------- |------------- |------------- |
| {#DB}.{#TABLE} Replica is readonly | WARNING | This mode is turned on if the config doesn't have sections with ZooKeeper, if an unknown error occurred when re-initializing sessions in ZooKeeper, and during session re-initialization in ZooKeeper. | min(/ClickHouse by HTTP/clickhouse.replica.is_readonly["{#DB}.{#TABLE}"],5m)=1 | [{"tag": "scope", "value": "availability"}] | no url |
| {#DB}.{#TABLE} Replica session is expired | WARNING | This mode is turned on if the config doesn't have sections with ZooKeeper, if an unknown error occurred when re-initializing sessions in ZooKeeper, and during session re-initialization in ZooKeeper. | min(/ClickHouse by HTTP/clickhouse.replica.is_session_expired["{#DB}.{#TABLE}"],5m)=1 | [{"tag": "scope", "value": "performance"}] | no url |
| {#DB}.{#TABLE}: Difference between log_max_index and log_pointer is too high | WARNING | no description | min(/ClickHouse by HTTP/clickhouse.replica.lag["{#DB}.{#TABLE}"],5m) > {$CLICKHOUSE.LOG_POSITION.DIFF.MAX.WARN} | [{"tag": "scope", "value": "availability"}] | no url |
| {#DB}.{#TABLE}: Too many operations in queue | WARNING | no description | min(/ClickHouse by HTTP/clickhouse.replica.queue_size["{#DB}.{#TABLE}"],5m)>{$CLICKHOUSE.QUEUE.SIZE.MAX.WARN:"{#TABLE}"} | [{"tag": "scope", "value": "performance"}] | no url |
| {#DB}.{#TABLE}: Number of active replicas less than number of total replicas | WARNING | no description | max(/ClickHouse by HTTP/clickhouse.replica.active_replicas["{#DB}.{#TABLE}"],5m) < last(/ClickHouse by HTTP/clickhouse.replica.total_replicas["{#DB}.{#TABLE}"]) | [{"tag": "scope", "value": "availability"}] | no url |


<a name="discovery_tables"></a>

## Discovery Tables

### Items

| name | description | key | type |
| ------------- |------------- |------------- |------------- |
| {#DB}.{#TABLE}: Bytes | Table size in bytes. Database: {#DB}, table: {#TABLE} | clickhouse.table.bytes["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Get table info | The item gets information about {#TABLE} table of {#DB} database. | clickhouse.table.info_raw["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Parts | Number of parts of the table. Database: {#DB}, table: {#TABLE} | clickhouse.table.parts["{#DB}.{#TABLE}"] | DEPENDENT |
| {#DB}.{#TABLE}: Rows | Number of rows in the table. Database: {#DB}, table: {#TABLE} | clickhouse.table.rows["{#DB}.{#TABLE}"] | DEPENDENT |

